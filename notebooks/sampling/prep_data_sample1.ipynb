{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SAMPLE 1\n",
    "\n",
    "This notebook was used to select a sample of 200 files for an exploratory annotation round. This round was performed by the project team before the beginning of the official annotations. The goals of this round were (a) to try out and refine the annotation guidelines, (b) to check whether keywords are useful / necessary for selection of files for annotation.\n",
    "\n",
    "**There is no need to re-run this notebook since its outputs are stored:**\n",
    "\n",
    "- the sample is stored here: `../../to_inception_conll/sample1.pkl`\n",
    "- the results of the keyword search are stored here: `../../data/keyword_results/`\n",
    "\n",
    "The sample contains 2 types of files:\n",
    "\n",
    "- Files that contain keywords from at least 6 different domains (**kwd**)\n",
    "- Randomly selected files (**rndm**)\n",
    "   \n",
    "Each of the 5 annotators received the following composition of files:\n",
    "\n",
    "- 2017 data: 5 kwd + 5 rndm\n",
    "- 2018 data: 5 kwd + 5 rndm\n",
    "- 2020 COVID diagnosis: 5 kwd + 5 rndm\n",
    "- 2020 other diagnoses: 5 kwd + 5 rndm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "from src.data_process.keyword_search import *\n",
    "from src.data_process.text_to_conll import row_to_conllfile\n",
    "from src.utils.df_funcs import remove_on_multikeys"
   ]
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../data')\n",
    "\n",
    "all_2017 = pd.read_pickle(path / '2017_raw/processed.pkl')\n",
    "all_2018 = pd.read_pickle(path / '2018_raw/processed.pkl')\n",
    "all_2020 = pd.read_pickle(path / '2020_raw/processed.pkl')\n",
    "cov_2020 = pd.read_pickle(path / '2020_raw/ICD_U07.1/notes_[U07.1]_2020_q1_q2_q3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cov_2020 = remove_on_multikeys(all_2020, cov_2020, ['MDN', 'NotitieID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = pd.read_csv(path / 'annotated_notes_ids.csv', dtype={'MDN': str, 'NotitieID': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_excel('../../keywords/keywords_v1.xlsx')"
   ]
  },
  {
   "source": [
    "# Sample for keyword search\n",
    "\n",
    "From each of the datasets (except cov_2020, see below), a random sample of 50,000 files was selected for the keyword search.\n",
    "\n",
    "**NOTE**: len(cov_2020) < 50000, therefore the full dataset is used rather than a sample."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude annotated 2017 notes\n",
    "\n",
    "non_annot_2017 = all_2017.loc[~all_2017.NotitieID.isin(annotated.query(\"year==2017\").NotitieID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_2017 = non_annot_2017.sample(50000, random_state=19)\n",
    "samp_2018 = all_2018.sample(50000, random_state=19)\n",
    "samp_non_cov_2020 = non_cov_2020.sample(50000, random_state=19)"
   ]
  },
  {
   "source": [
    "# Keyword search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "samp_2017: len(df)=50000\n",
      "Results len(df)=28705 are saved to ../../data/keyword_results/samp_2017_kwd_v1.pkl\n",
      "0:01:03.431036\n",
      "samp_2018: len(df)=50000\n",
      "Results len(df)=29166 are saved to ../../data/keyword_results/samp_2018_kwd_v1.pkl\n",
      "0:01:07.358767\n",
      "samp_non_cov_2020: len(df)=50000\n",
      "Results len(df)=30695 are saved to ../../data/keyword_results/samp_non_cov_2020_kwd_v1.pkl\n",
      "0:01:11.967306\n",
      "cov_2020: len(df)=44938\n",
      "Results len(df)=35160 are saved to ../../data/keyword_results/cov_2020_kwd_v1.pkl\n",
      "0:01:06.797263\n"
     ]
    }
   ],
   "source": [
    "keywords['regex'] = keywords.apply(lambda row: get_regex(row.keyword, row.regex_template_id), axis=1)\n",
    "reg_dict = get_reg_dict(keywords)\n",
    "domains = ['ENR', 'ATT', 'STM', 'ADM', 'INS', 'MBW', 'FAC', 'BER']\n",
    "\n",
    "dfs = [samp_2017, samp_2018, samp_non_cov_2020, cov_2020]\n",
    "\n",
    "for df in dfs:\n",
    "    print(f\"{df.name}: {len(df)=}\")\n",
    "    outfile = path / f\"keyword_results/{df.name}_kwd_v1.pkl\"\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    df = find_keywords(df, reg_dict)\n",
    "    save_kwd_results(df, domains, outfile)\n",
    "\n",
    "    print(datetime.now() - start_time)"
   ]
  },
  {
   "source": [
    "# Select notes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwd_2017 = pd.read_pickle(path / 'keyword_results/samp_2017_kwd_v1.pkl')\n",
    "kwd_2018 = pd.read_pickle(path / 'keyword_results/samp_2018_kwd_v1.pkl')\n",
    "kwd_non_cov_2020 = pd.read_pickle(path / 'keyword_results/samp_non_cov_2020_kwd_v1.pkl')\n",
    "kwd_cov_2020 = pd.read_pickle(path / 'keyword_results/cov_2020_kwd_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude annotated covid 2020 notes\n",
    "\n",
    "kwd_cov_2020 = remove_on_multikeys(kwd_cov_2020, annotated, ['MDN', 'NotitieID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwd_df = pd.concat(\n",
    "    [kwd_2017, kwd_2018, kwd_non_cov_2020, kwd_cov_2020],\n",
    "    keys=['2017', '2018', 'non_cov_2020', 'cov_2020'],\n",
    "    names=['source', 'source_idx'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['ENR', 'ATT', 'STM', 'ADM', 'INS', 'MBW', 'FAC', 'BER']\n",
    "matched_domains = [f\"matched_{domain}\" for domain in domains]\n",
    "count_domains = [f\"n_{domain}\" for domain in domains]\n",
    "\n",
    "def op_count(df, domain):\n",
    "    \"Number of matches for `domain` keywords.\"\n",
    "    return df[domain].apply(len)\n",
    "\n",
    "def op_bool(df, domain):\n",
    "    \"Are there any matches for `domain` keywords (boolean).\"\n",
    "    return df[domain].apply(bool)\n",
    "\n",
    "ops_count = {f\"n_{domain}\":partial(op_count, domain=domain) for domain in domains}\n",
    "ops_bool = {f\"matched_{domain}\":partial(op_bool, domain=domain) for domain in domains}\n",
    "\n",
    "kwd_df = kwd_df.assign(**ops_count, **ops_bool).assign(n_domains=lambda df: df[matched_domains].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "source      2017   2018  cov_2020  non_cov_2020  Totals\n",
       "n_domains                                              \n",
       "1          12373  12017     10066         11647   46103\n",
       "2           7672   7695      8810          8202   32379\n",
       "3           4557   4702      6673          5361   21293\n",
       "4           2319   2538      4077          3142   12076\n",
       "5           1095   1361      2151          1460    6067\n",
       "6            456    572       961           629    2618\n",
       "7            184    211       458           205    1058\n",
       "8             49     70       281            49     449\n",
       "Totals     28705  29166     33477         30695  122043"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>source</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>cov_2020</th>\n      <th>non_cov_2020</th>\n      <th>Totals</th>\n    </tr>\n    <tr>\n      <th>n_domains</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>12373</td>\n      <td>12017</td>\n      <td>10066</td>\n      <td>11647</td>\n      <td>46103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7672</td>\n      <td>7695</td>\n      <td>8810</td>\n      <td>8202</td>\n      <td>32379</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4557</td>\n      <td>4702</td>\n      <td>6673</td>\n      <td>5361</td>\n      <td>21293</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2319</td>\n      <td>2538</td>\n      <td>4077</td>\n      <td>3142</td>\n      <td>12076</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1095</td>\n      <td>1361</td>\n      <td>2151</td>\n      <td>1460</td>\n      <td>6067</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>456</td>\n      <td>572</td>\n      <td>961</td>\n      <td>629</td>\n      <td>2618</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>184</td>\n      <td>211</td>\n      <td>458</td>\n      <td>205</td>\n      <td>1058</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>49</td>\n      <td>70</td>\n      <td>281</td>\n      <td>49</td>\n      <td>449</td>\n    </tr>\n    <tr>\n      <th>Totals</th>\n      <td>28705</td>\n      <td>29166</td>\n      <td>33477</td>\n      <td>30695</td>\n      <td>122043</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "kwd_df.reset_index().pivot_table(\n",
    "    columns=['source',],\n",
    "    index=['n_domains'],\n",
    "    aggfunc='count',\n",
    "    values='NotitieID',\n",
    "    margins=True,\n",
    "    margins_name='Totals',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    '2017': samp_2017,\n",
    "    '2018': samp_2018,\n",
    "    'cov_2020': remove_on_multikeys(cov_2020, annotated, ['MDN', 'NotitieID']),\n",
    "    'non_cov_2020': samp_non_cov_2020,\n",
    "}\n",
    "\n",
    "def select_kwds_and_rndm_from_data(data, kwd_df):\n",
    "    kwd_samples = kwd_df.query(\"n_domains > 5\").groupby(level=0).sample(25)\n",
    "    add_source = lambda df, source: pd.concat([df], keys=[source])\n",
    "    all_selected = []\n",
    "    for source, df in data.items():\n",
    "        selected_kwds = df.loc[kwd_samples.xs(source).index]\n",
    "        selected_rndm = df.loc[~df.index.isin(selected_kwds.index)].sample(25)\n",
    "        dfs = [selected_kwds, selected_rndm]\n",
    "        all_selected.append(pd.concat(dfs, keys=['kwds', 'rndm']).pipe(add_source, source))\n",
    "    return pd.concat(all_selected).rename_axis(['source', 'samp_meth', 'source_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = select_kwds_and_rndm_from_data(data, kwd_df)\n",
    "sample.to_pickle(path / 'to_inception_conll/sample1.pkl')"
   ]
  },
  {
   "source": [
    "# Convert to CoNLL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(path / 'to_inception_conll/sample1.pkl').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "conllpath = path / 'to_inception_conll/sample1'\n",
    "\n",
    "annotators = [\n",
    "    'edwin',\n",
    "    'sabina',\n",
    "    'carel',\n",
    "    'caroline',\n",
    "    'marike'\n",
    "]\n",
    "\n",
    "nlp = spacy.load('nl_core_news_sm')\n",
    "\n",
    "for idx, annotator in enumerate(annotators):\n",
    "    \n",
    "    outdir = conllpath / annotator\n",
    "    outdir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # select sample indices\n",
    "    base = list(range(5))\n",
    "    base_range = [i + (25 * n) for n in range(8) for i in base]\n",
    "    selection = [i+5*idx for i in base_range]\n",
    "    \n",
    "    # convert to conll\n",
    "    df = sample.iloc[selection]\n",
    "    df.apply(row_to_conllfile, axis=1, nlp=nlp, outdir=outdir, batch='sample1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}